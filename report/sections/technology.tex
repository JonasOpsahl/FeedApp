\section{Technology Assessment}
\label{sec:technology}


(Remove later: Introduce in sufficient depth the key concepts and architecture of the chosen software technology. As part of this, you may consider using a running example to introduce the technology.)


At its core, Apache Kafka is a distributed event streaming platform. Think of it
as a highly scalable, fault-tolerant, and durable "log file" that different parts
of an application can write to and read from simultaneously. The \texttt{FeedApp}
project uses these core concepts to decouple tasks. When a user votes, the
system does not immediately try to update every other user's screen. Instead, it
publishes an "event" to Kafka, and other services (like the WebSocket
broadcaster) react to that event.

\subsubsection*{Event:}
An event is the most basic unit of data, representing the
fact that "something happened."
In the \texttt{FeedApp}, an event is a
\texttt{Map<String, Object>} that gets serialized into JSON. For example, when
a poll is created, the \texttt{PollEventListener} creates an event with the
\texttt{pollId}, \texttt{question}, and \texttt{eventType}.
The consumer listens for vote change events, which it receives
as a \texttt{Map} containing the \texttt{pollId} and \texttt{optionOrder}.

\subsubsection*{Topic:}
A topic is a named "category" or "feed" where events are
stored and published. A cluster can host many topics, and with KRaft
mode, the number of topics can now scale into the millions \cite{kafka_topics}.
The \texttt{FeedApp} uses a dynamic topic strategy.
Instead of one giant \texttt{votes} topic, the \texttt{PollTopicManager}
creates a unique topic for every single poll.
For example, for a poll with ID \texttt{10}, the topic name would be
\texttt{poll.voteChange.10}.

\subsubsection*{Producer:}
A producer is a client application that writes
events to a Kafka topic.
The \texttt{ProducerService} in the FeedApp project is a classic producer,
using Spring's \texttt{KafkaTemplate} to send events.
This service is used by the \texttt{PollEventListener} to send a message
after a new poll is successfully saved to the database.
With the 3-node cluster, the producer (our backend) is given a list
of all three brokers (\texttt{kafka-1:29092,kafka-2:29092,kafka-3:29092})
via its environment variables. The Kafka
client uses this list to discover the entire cluster.

\subsubsection*{Consumer:}
A consumer is a client application that reads (subscribes
to) events from one or more Kafka topics.
The \texttt{ConsumerService} acts as the consumer
.
It uses a powerful feature to match the dynamic topic strategy: it listens to a
\texttt{topicPattern} (\texttt{"poll.voteChange.*"}) instead of a fixed topic
name. This allows it to automatically discover and consume from new poll topics
as soon as they are created.

\subsubsection*{Consumer Group:}
A set of consumers that work together to process events
from topics. Kafka guarantees that each event in a topic's partition is
delivered to only one consumer instance within that group.
The \texttt{FeedApp} defines the consumer group ID
as \texttt{"poll-app"} in its \texttt{application.\allowbreak properties} file.
If one were to run multiple instances of the backend service for scalability,
they would all share this group ID. Kafka would then automatically balance the
load of all the poll topics among them.

\subsubsection*{Partition:}
{\sloppy
Partitions are the core of Kafka's scalability. A topic is
split into one or more partitions. Each partition is an ordered, immutable log
of events, which can be hosted on different brokers.
The \texttt{FeedApp} project makes a specific design
choice. When the \texttt{PollTopicManager} creates a new topic, it is
configured with one partition to guarantee strict event ordering for
that poll. To match the 3-node cluster's fault-tolerant
design, the replication factor is set to 3. This is implemented
by calling \texttt{new NewTopic} with the parameters
\texttt{(topicName, 1, (short) 3)}.
This configuration ensures the single partition is copied to all three brokers,
providing fault tolerance and high availability.
}

\subsubsection*{Broker:}
A broker is a single Kafka server. Brokers receive messages
from producers, assign offsets to them, and commit them to the partition log on
disk, which provides Kafka's durability.
The provided \texttt{docker-compose.yml}
file defines three distinct broker services: \texttt{kafka-1}, \texttt{kafka-2},
and \texttt{kafka-3}. Each of these nodes
is configured with the \texttt{broker} role.

\subsubsection*{Cluster:}
A Kafka cluster is a group of brokers working together to
provide scalability, availability, and fault tolerance. Partitions are
replicated on multiple brokers based on the topic's replication factor.
The three brokers (\texttt{kafka-1},
\texttt{kafka-2}, \texttt{kafka-3}) form the cluster.
This is where the concept of a replication factor of 3 becomes reality.
When \texttt{PollTopicManager} creates \texttt{poll.voteChange.10} with 3
replicas, that topic's single partition is copied to all three brokers. One
broker is elected "leader" for that partition (handling all writes), while the
other two are "followers." If the leader fails, a follower is
promoted, ensuring no data loss. This entire process is managed by the KRaft
controller quorum, which in this 3-node setup consists of all three nodes
(\texttt{KAFKA\_CONTROLLER\_QUORUM\_VOTERS: '1@kafka-1:9093,...'}).

This part and other parts of the report probably needs to refer to
figures. Figure~\ref{fig:framework} from \cite{brown:96} just
illustrates how figure can be included in the report.

\begin{figure}[thb]
	\centering
	\includegraphics[scale=0.5]{figs/framework.png}
	\caption{Software technology evaluation framework.}
	\label{fig:framework}
\end{figure}

\subsection{Descriptive Modeling}

write where the technology comes from, its history, its context and what problem it solves.
Consider drawing a graph like in \cite{brown:96}.

\subsection{Experiment Design}

Write you hypotheses about what benefits the technology bring and how you can support or reject them via experiments.

\subsection{Experiment Evaluation}

Write about the results of your experiments, either via personal experience reports, quantitative benchmarks, a demostrator case study or a combination of multiple approaches.


For some reports you may have to include a table with experimental
results are other kinds of tables that for instance compares
technologies. Table~\ref{tab:results} gives an example of how to create a table.

\begin{table}[bth]
	\centering
	\begin{tabular}{llrrrrrr}
		Config & Property & States & Edges & Peak & E-Time & C-Time & T-Time
		\\ \hline \hline
		22-2 & A   &    7,944  &   22,419  &  6.6  \%  &  7 ms & 42.9\% &  485.7\% \\
		22-2 & A   &    7,944  &   22,419  &  6.6  \%  &  7 ms & 42.9\% &  471.4\% \\
		30-2 & B   &   14,672  &   41,611  &  4.9  \%  & 14 ms & 42.9\% &  464.3\% \\
		30-2 & C   &   14,672  &   41,611  &  4.9  \%  & 15 ms & 40.0\% &  420.0\% \\ \hline
		10-3 & D   &   24,052  &   98,671  & 19.8  \%  & 35 ms & 31.4\% &  285.7\% \\
		10-3 & E   &   24,052  &   98,671  & 19.8  \%  & 35 ms & 34.3\% &  308.6\% \\
		\hline \hline
	\end{tabular}
	\caption{Selected experimental results on the communication protocol example.}
	\label{tab:results}
\end{table}
